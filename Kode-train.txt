# ============================================================
# IMPORT LIBRARY
# ============================================================
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive, files
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
import glob

warnings.filterwarnings('ignore')

# ============================================================
# GOOGLE DRIVE
# ============================================================
try:
    drive.mount('/content/drive')
    print("‚úÖ Google Drive berhasil terhubung.")
except Exception as e:
    print(f"‚ùå Gagal menghubungkan Google Drive: {e}")

# ============================================================
# PEMETAAN LABEL
# ============================================================
BASE_PATH = '/content/drive/My Drive/Fake Data/'

label_map = {
    'Sapi': 'Tidak Terdeteksi',
    'Babi': 'Terdeteksi Daging Babi',
    'Sapi Babi': 'Terdeteksi Daging Babi'
}

# ============================================================
# FUNGSI EKSTRAKSI FITUR SENSOR
# ============================================================
def extract_features(df):
    """Ekstraksi fitur statistik + rasio dari 8 sensor gas."""
    
    sensors = ['MQ2', 'MQ3', 'MQ4', 'MQ6', 'MQ7', 'MQ8', 'MQ135', 'QCM']
    features = {}
    epsilon = 1e-6

    for col in sensors:
        if col not in df.columns:
            print(f"‚ö† Kolom '{col}' tidak ditemukan ‚Üí isi 0")
            for stat in ['mean', 'std', 'min', 'max', 'range', 'skew', 'kurt']:
                features[f'{col}_{stat}'] = 0
            continue

        # Konversi jika ada koma
        if df[col].dtype == 'object':
            df[col] = pd.to_numeric(df[col].str.replace(',', '.'), errors='coerce')

        df[col] = df[col].fillna(0)

        features[f'{col}_mean'] = df[col].mean()
        features[f'{col}_std'] = df[col].std()
        features[f'{col}_min'] = df[col].min()
        features[f'{col}_max'] = df[col].max()
        features[f'{col}_range'] = df[col].max() - df[col].min()
        features[f'{col}_skew'] = df[col].skew()
        features[f'{col}_kurt'] = df[col].kurtosis()

    # Rasio penting
    features['mq2_mq135_ratio'] = features['MQ2_mean'] / (features['MQ135_mean'] + epsilon)
    features['mq3_mq135_ratio'] = features['MQ3_mean'] / (features['MQ135_mean'] + epsilon)
    features['mq4_mq135_ratio'] = features['MQ4_mean'] / (features['MQ135_mean'] + epsilon)

    # Rasio ke QCM
    for s in ['MQ2','MQ3','MQ4','MQ6','MQ7','MQ8','MQ135']:
        features[f"{s}_qcm_ratio"] = features[f"{s}_mean"] / (features["QCM_mean"] + epsilon)

    return features


# ============================================================
# LOAD SELURUH DATASET
# ============================================================
all_features = []
all_labels = []

print("\nMemuat seluruh file CSV...\n")

for folder_name, label in label_map.items():
    folder_path = os.path.join(BASE_PATH, folder_name)
    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

    if not csv_files:
        print(f"‚ö† Folder '{folder_name}' kosong!")
        continue

    print(f"üìÇ Folder: {folder_name} ‚Üí {len(csv_files)} file")

    for file_path in csv_files:
        try:
            df = pd.read_csv(file_path, sep=';', decimal=',')
            features = extract_features(df)
            all_features.append(features)
            all_labels.append(label)
        except Exception as e:
            print(f"‚ùå Error {file_path}: {e}")


# ============================================================
# DATAFRAME FITUR
# ============================================================
X_df = pd.DataFrame(all_features).fillna(0)
y_series = pd.Series(all_labels, name="Label")

print("\nTotal dataset:", len(X_df))
print("\nDistribusi kelas:")
print(y_series.value_counts())

# ============================================================
# PREPROCESSING
# ============================================================
le = LabelEncoder()
y = le.fit_transform(y_series)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_df)

# SPLIT DATA
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.10, random_state=42, stratify=y
)

print("\nData latih:", len(X_train), " | Data uji:", len(X_test))

# ============================================================
# TRAINING SVM
# ============================================================
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'linear']
}

grid = GridSearchCV(SVC(probability=True), param_grid, cv=3, refit=True)
grid.fit(X_train, y_train)

best_model = grid.best_estimator_
print("\nParameter terbaik:", grid.best_params_)

# ============================================================
# EVALUASI MODEL
# ============================================================
y_pred = best_model.predict(X_test)

print("\n--- HASIL EVALUASI ---")
print(classification_report(y_test, y_pred, target_names=le.classes_))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(7, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# ============================================================
# FUNGSI PREDIKSI FILE BARU
# ============================================================
def predict_new_sample(file_path):
    print("\nüîç Menguji file:", file_path)
    try:
        df = pd.read_csv(file_path, sep=';', decimal=',')
        features = extract_features(df)

        df_features = pd.DataFrame([features], columns=X_df.columns).fillna(0)
        scaled = scaler.transform(df_features)

        pred = best_model.predict(scaled)
        proba = best_model.predict_proba(scaled)

        label = le.inverse_transform(pred)[0]
        confidence = np.max(proba) * 100

        print(f"‚û° HASIL: {label} ({confidence:.2f}% yakin)")
    except Exception as e:
        print("‚ùå ERROR:", e)

# ============================================================
# UPLOAD FILE UNTUK PREDIKSI
# ============================================================
print("\nSilakan upload file CSV untuk diuji:")
uploaded = files.upload()

for fname in uploaded.keys():
    predict_new_sample(fname)